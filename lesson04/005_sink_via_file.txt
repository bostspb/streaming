[student782_3@bigdataanalytics2-worker-shdpt-v31-1-0 ~]$ /spark2.4/bin/pyspark --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.7 --driver-memory 512m --num-executors 1 --executor-memory 512m --master local[4]
Python 2.7.5 (default, Nov 16 2020, 22:23:17)
[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
Warning: Ignoring non-Spark config property: hive.metastore.uris
Ivy Default Cache set to: /home/student782_3/.ivy2/cache
The jars for the packages stored in: /home/student782_3/.ivy2/jars
:: loading settings :: url = jar:file:/spark2.4/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
org.apache.spark#spark-sql-kafka-0-10_2.11 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-de6fade9-e87d-4e18-9657-a6574021b2da;1.0
        confs: [default]
        found org.apache.spark#spark-sql-kafka-0-10_2.11;2.4.7 in central
        found org.apache.kafka#kafka-clients;2.0.0 in central
        found org.lz4#lz4-java;1.4.0 in central
        found org.xerial.snappy#snappy-java;1.1.7.5 in central
        found org.slf4j#slf4j-api;1.7.16 in central
        found org.spark-project.spark#unused;1.0.0 in central
:: resolution report :: resolve 408ms :: artifacts dl 8ms
        :: modules in use:
        org.apache.kafka#kafka-clients;2.0.0 from central in [default]
        org.apache.spark#spark-sql-kafka-0-10_2.11;2.4.7 from central in [default]
        org.lz4#lz4-java;1.4.0 from central in [default]
        org.slf4j#slf4j-api;1.7.16 from central in [default]
        org.spark-project.spark#unused;1.0.0 from central in [default]
        org.xerial.snappy#snappy-java;1.1.7.5 from central in [default]
        ---------------------------------------------------------------------
        |                  |            modules            ||   artifacts   |
        |       conf       | number| search|dwnlded|evicted|| number|dwnlded|
        ---------------------------------------------------------------------
        |      default     |   6   |   0   |   0   |   0   ||   6   |   0   |
        ---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-de6fade9-e87d-4e18-9657-a6574021b2da
        confs: [default]
        0 artifacts copied, 6 already retrieved (0kB/8ms)
21/08/09 08:11:59 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.4.7
      /_/

Using Python version 2.7.5 (default, Nov 16 2020 22:23:17)
SparkSession available as 'spark'.
>>> from pyspark.sql import SparkSession
>>> from pyspark.sql import functions as F
>>> from pyspark.sql.types import StructType, StringType
>>>
>>>
>>> spark = SparkSession.builder.appName("spark_sinks_app").getOrCreate()
>>>
>>> in_memory_table_name = "memory_output_table"
>>> output_path = "tmp/orders_file_output"
>>> checkpoint_location = "tmp/orders_checkpoint"
>>>
>>> # Read stream from Kafka #
... # ====================== #
... source_topic = "orders_topic_json"
>>> target_row_topic = "orders_modified_topic_row"
>>> target_json_topic = "orders_modified_topic_json"
>>>
>>> kafka_brokers = "bigdataanalytics2-worker-shdpt-v31-1-0:6667"
>>>
>>> # read stream
... raw_orders = spark.readStream. \
...     format("kafka"). \
...     option("kafka.bootstrap.servers", kafka_brokers). \
...     option("subscribe", source_topic). \
...     option("maxOffsetsPerTrigger", "50"). \
...     option("startingOffsets", "earliest"). \
...     load()
>>>
>>> schema = StructType() \
...     .add("order_id", StringType()) \
...     .add("customer_id", StringType()) \
...     .add("order_status", StringType()) \
...     .add("order_purchase_timestamp", StringType()) \
...     .add("order_approved_at", StringType()) \
...     .add("order_delivered_carrier_date", StringType()) \
...     .add("order_delivered_customer_date", StringType()) \
...     .add("order_estimated_delivery_date", StringType())
>>>
>>> parsed_orders = raw_orders \
...     .select(F.from_json(F.col("value").cast("String"), schema).alias("value"), "offset") \
...     .select("value.*")
>>> def file_output(df, freq):
...     return df\
...         .writeStream\
...         .format("parquet") \
...         .trigger(processingTime='%s seconds' % freq) \
...         .option("path", output_path) \
...         .option("checkpointLocation", checkpoint_location) \
...         .start()
...
>>> stream = file_output(parsed_orders, 5)
21/08/09 08:12:27 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
21/08/09 08:12:34 WARN streaming.ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 5000 milliseconds, but spent 6316 milliseconds
stream.stop()
>>> exit()
[student782_3@bigdataanalytics2-worker-shdpt-v31-1-0 ~]$ hdfs dfs -ls tmp/orders_file_output
Found 37 items
drwxr-xr-x   - student782_3 hdfs          0 2021-08-09 08:13 tmp/orders_file_output/_spark_metadata
-rw-r--r--   2 student782_3 hdfs       4994 2021-08-09 08:12 tmp/orders_file_output/part-00000-1531b140-a91f-4f5f-8eb2-e63bff54d0cc-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4917 2021-08-09 08:13 tmp/orders_file_output/part-00000-1670c75c-a0d9-4719-96b1-e5aeffd8ebc8-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4907 2021-08-09 08:13 tmp/orders_file_output/part-00000-45ac5066-90db-4602-9259-bfd9c89be5d8-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4884 2021-08-09 08:12 tmp/orders_file_output/part-00000-58761b54-5b28-498a-aecf-87390a8046b7-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4820 2021-08-09 08:13 tmp/orders_file_output/part-00000-720ac1aa-9388-4625-ae72-97d41af7d2b0-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4967 2021-08-09 08:12 tmp/orders_file_output/part-00000-823b474a-ec6f-4c65-801f-599d92796642-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4969 2021-08-09 08:12 tmp/orders_file_output/part-00000-a0a2876c-a1af-4ce4-b6ad-842e47eef2cc-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4958 2021-08-09 08:13 tmp/orders_file_output/part-00000-b0fd49da-f690-47f3-9a34-2bf09f11b9fa-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4895 2021-08-09 08:12 tmp/orders_file_output/part-00000-b1324795-c741-4fc8-9c79-f9cc982cc5ce-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4842 2021-08-09 08:12 tmp/orders_file_output/part-00000-c484dfc2-8d05-4a86-a869-6f6397875557-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       5035 2021-08-09 08:12 tmp/orders_file_output/part-00000-cd51aca2-dde2-4c6e-aaf3-6a917dabbb2e-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       5005 2021-08-09 08:13 tmp/orders_file_output/part-00000-d28277e9-a954-431a-816e-e40e19a9ff4a-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4897 2021-08-09 08:12 tmp/orders_file_output/part-00001-10079009-1e9d-45f6-9607-5d03eb5b08db-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4907 2021-08-09 08:13 tmp/orders_file_output/part-00001-1570510d-10a1-4bc7-b7bb-5b051a588bbf-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4850 2021-08-09 08:12 tmp/orders_file_output/part-00001-242e8854-ac2b-4cfd-83ce-23899531f056-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4994 2021-08-09 08:13 tmp/orders_file_output/part-00001-52aaf751-731e-410c-9fcd-b3540ec616c1-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4851 2021-08-09 08:12 tmp/orders_file_output/part-00001-8c9433f7-4a2e-44e3-ab10-ec6e5fca09d4-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4799 2021-08-09 08:12 tmp/orders_file_output/part-00001-9511b37d-682b-40d3-b512-59842f11f17a-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4933 2021-08-09 08:13 tmp/orders_file_output/part-00001-a065a6d6-b105-4e28-a565-a70d3698f3a5-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4998 2021-08-09 08:12 tmp/orders_file_output/part-00001-caad6372-ae6a-458a-945b-3d11b10df5e9-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4888 2021-08-09 08:12 tmp/orders_file_output/part-00001-d51c8325-10af-4f2a-8baa-4e8b185b901c-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       5010 2021-08-09 08:13 tmp/orders_file_output/part-00001-eebfe1cf-ad92-4125-a1de-e0547e198693-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4953 2021-08-09 08:12 tmp/orders_file_output/part-00001-f3e36390-63b7-43e0-8d9f-7848a205cf3b-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4975 2021-08-09 08:13 tmp/orders_file_output/part-00001-fc1b6a61-bfd1-425a-a717-fd154623bf52-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4873 2021-08-09 08:12 tmp/orders_file_output/part-00002-0af7d4d4-2639-4cfb-8558-3fe1ed3b6855-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4834 2021-08-09 08:12 tmp/orders_file_output/part-00002-1c55758c-ae2d-4e93-a925-8254e3ec0478-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       5002 2021-08-09 08:13 tmp/orders_file_output/part-00002-1dbc3604-ca28-4cd7-b986-cb267b2d90a1-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       5002 2021-08-09 08:12 tmp/orders_file_output/part-00002-6b275c7b-1897-4480-aab5-a1e188f5d2bc-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4985 2021-08-09 08:13 tmp/orders_file_output/part-00002-80bc0645-0b65-4b50-a06b-b83d1f0a8e09-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4963 2021-08-09 08:12 tmp/orders_file_output/part-00002-9453ccf9-19cc-4e74-bb63-862f2bb5e489-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4986 2021-08-09 08:12 tmp/orders_file_output/part-00002-968c6098-a827-4b0c-b96d-73b6aaa11584-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4993 2021-08-09 08:13 tmp/orders_file_output/part-00002-9e35db3c-9f56-4e82-a4a9-f00225ace1f8-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4894 2021-08-09 08:13 tmp/orders_file_output/part-00002-a54a2ef5-5e02-436e-8eb4-17a11a160edb-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4968 2021-08-09 08:12 tmp/orders_file_output/part-00002-bf3c8e58-970a-4706-a09c-679f137c889a-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4984 2021-08-09 08:12 tmp/orders_file_output/part-00002-d9279c65-8474-4eb6-8e53-decca24bc453-c000.snappy.parquet
-rw-r--r--   2 student782_3 hdfs       4962 2021-08-09 08:13 tmp/orders_file_output/part-00002-e15f46eb-69ff-493e-8e68-ef6d59423815-c000.snappy.parquet
[student782_3@bigdataanalytics2-worker-shdpt-v31-1-0 ~]$
