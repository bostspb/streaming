[student782_3@bigdataanalytics2-worker-shdpt-v31-1-0 ~]$ /spark2.4/bin/spark-submit 7.2.spark_submit_finite_stream.py
Warning: Ignoring non-Spark config property: hive.metastore.uris
21/08/17 05:38:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/08/17 05:38:39 INFO spark.SparkContext: Running Spark version 2.4.7
21/08/17 05:38:39 INFO spark.SparkContext: Submitted application: spark-submit-finite-stream-app
21/08/17 05:38:39 INFO spark.SecurityManager: Changing view acls to: student782_3
21/08/17 05:38:39 INFO spark.SecurityManager: Changing modify acls to: student782_3
21/08/17 05:38:39 INFO spark.SecurityManager: Changing view acls groups to:
21/08/17 05:38:39 INFO spark.SecurityManager: Changing modify acls groups to:
21/08/17 05:38:39 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(student782_3); groups with view permissions: Set(); users  with modify permissions: Set(student
782_3); groups with modify permissions: Set()
21/08/17 05:38:39 INFO util.Utils: Successfully started service 'sparkDriver' on port 35391.
21/08/17 05:38:39 INFO spark.SparkEnv: Registering MapOutputTracker
21/08/17 05:38:39 INFO spark.SparkEnv: Registering BlockManagerMaster
21/08/17 05:38:39 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/08/17 05:38:39 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/08/17 05:38:39 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-1d52b0f6-0ad4-4583-a009-b3079af51be1
21/08/17 05:38:39 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB
21/08/17 05:38:39 INFO spark.SparkEnv: Registering OutputCommitCoordinator
21/08/17 05:38:39 INFO util.log: Logging initialized @2635ms
21/08/17 05:38:39 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
21/08/17 05:38:39 INFO server.Server: Started @2725ms
21/08/17 05:38:39 INFO server.AbstractConnector: Started ServerConnector@1cf977f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
21/08/17 05:38:39 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4ab19f74{/jobs,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@22ad33e5{/jobs/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2746f077{/jobs/job,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65e0898b{/jobs/job/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2e99acc9{/stages,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3ecc2425{/stages/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6eb99f75{/stages/stage,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@335a199f{/stages/stage/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@113a7ab6{/stages/pool,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3999dc56{/stages/pool/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@12732773{/storage,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@71864243{/storage/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@332b790f{/storage/rdd,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@44277850{/storage/rdd/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4f649718{/environment,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@c3340ed{/environment/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6438a365{/executors,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1b22a24a{/executors/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70152a61{/executors/threadDump,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@66b728a6{/executors/threadDump/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@47b58c9e{/static,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5fef9e92{/,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@696b535c{/api,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@66d2db98{/jobs/job/kill,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@69118af6{/stages/stage/kill,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://bigdataanalytics2-worker-shdpt-v31-1-0.novalocal:4040
21/08/17 05:38:40 INFO executor.Executor: Starting executor ID driver on host localhost
21/08/17 05:38:40 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46748.
21/08/17 05:38:40 INFO netty.NettyBlockTransferService: Server created on bigdataanalytics2-worker-shdpt-v31-1-0.novalocal:46748
21/08/17 05:38:40 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/08/17 05:38:40 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, bigdataanalytics2-worker-shdpt-v31-1-0.novalocal, 46748, None)
21/08/17 05:38:40 INFO storage.BlockManagerMasterEndpoint: Registering block manager bigdataanalytics2-worker-shdpt-v31-1-0.novalocal:46748 with 366.3 MB RAM, BlockManagerId(driver, bigdataanalytics2-worker-shdpt-v31-1-0.novalocal, 467
48, None)
21/08/17 05:38:40 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, bigdataanalytics2-worker-shdpt-v31-1-0.novalocal, 46748, None)
21/08/17 05:38:40 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, bigdataanalytics2-worker-shdpt-v31-1-0.novalocal, 46748, None)
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@581ba9df{/metrics/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO internal.SharedState: loading hive config file: file:/spark2.4/conf/hive-site.xml
21/08/17 05:38:40 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('/apps/spark/warehouse').
21/08/17 05:38:40 INFO internal.SharedState: Warehouse path is '/apps/spark/warehouse'.
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f3c4ed5{/SQL,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d2c825f{/SQL/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@bed3c03{/SQL/execution,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56852e05{/SQL/execution/json,null,AVAILABLE,@Spark}
21/08/17 05:38:40 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b71e6ca{/static/sql,null,AVAILABLE,@Spark}
21/08/17 05:38:41 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/08/17 05:38:41 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
21/08/17 05:38:42 INFO datasources.InMemoryFileIndex: It took 105 ms to list leaf files for 1 paths.
21/08/17 05:38:44 INFO streaming.CheckpointFileManager: Writing atomically to hdfs://bigdataanalytics2-head-shdpt-v31-1-0.novalocal:8020/user/student782_3/tmp/checkpoint/20210817053844/metadata using temp file hdfs://bigdataanalytics2-
head-shdpt-v31-1-0.novalocal:8020/user/student782_3/tmp/checkpoint/20210817053844/.metadata.2e3784f0-982c-486d-b36f-9abf9ebb12bf.tmp
21/08/17 05:38:44 INFO streaming.CheckpointFileManager: Renamed temp file hdfs://bigdataanalytics2-head-shdpt-v31-1-0.novalocal:8020/user/student782_3/tmp/checkpoint/20210817053844/.metadata.2e3784f0-982c-486d-b36f-9abf9ebb12bf.tmp to
hdfs://bigdataanalytics2-head-shdpt-v31-1-0.novalocal:8020/user/student782_3/tmp/checkpoint/20210817053844/metadata
21/08/17 05:38:44 INFO streaming.MicroBatchExecution: Starting [id = c2646243-b058-476e-ba52-a76f816ad68e, runId = 5248c6e9-3402-405b-a399-c6c0ec201918]. Use hdfs://bigdataanalytics2-head-shdpt-v31-1-0.novalocal:8020/user/student782_3/
tmp/checkpoint/20210817053844 to store the query checkpoint.
21/08/17 05:38:44 INFO streaming.FileStreamSourceLog: Set the compact interval to 10 [defaultCompactInterval: 10]
21/08/17 05:38:44 INFO spark.SparkContext: Invoking stop() from shutdown hook
21/08/17 05:38:44 INFO streaming.FileStreamSource: maxFilesPerBatch = None, maxFileAgeMs = 604800000
21/08/17 05:38:44 INFO streaming.MicroBatchExecution: Using Source [FileStreamSource[hdfs://bigdataanalytics2-head-shdpt-v31-1-0.novalocal:8020/user/student782_3/process_csv_as_stream]] from DataSourceV1 named 'FileSource[process_csv_a
s_stream]' [DataSource(org.apache.spark.sql.SparkSession@12376012,csv,List(),Some(StructType(StructField(product_category_name,StringType,true), StructField(product_category_name_english,StringType,true))),List(),None,Map(header -> tru
e, path -> process_csv_as_stream),None)]
21/08/17 05:38:44 INFO server.AbstractConnector: Stopped Spark@1cf977f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
21/08/17 05:38:44 INFO ui.SparkUI: Stopped Spark web UI at http://bigdataanalytics2-worker-shdpt-v31-1-0.novalocal:4040
21/08/17 05:38:44 INFO streaming.MicroBatchExecution: Starting new streaming query.
21/08/17 05:38:44 INFO streaming.MicroBatchExecution: Stream started from {}
21/08/17 05:38:44 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/08/17 05:38:44 INFO memory.MemoryStore: MemoryStore cleared
21/08/17 05:38:44 INFO storage.BlockManager: BlockManager stopped
21/08/17 05:38:44 INFO datasources.InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
21/08/17 05:38:44 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
21/08/17 05:38:44 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/08/17 05:38:44 INFO spark.SparkContext: Successfully stopped SparkContext
21/08/17 05:38:44 INFO util.ShutdownHookManager: Shutdown hook called
21/08/17 05:38:44 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-dbfeb570-0215-420b-aef7-1afc684d5384/pyspark-8d9b551a-a02e-4ad5-8063-b57eb712b7c0
21/08/17 05:38:44 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-dbfeb570-0215-420b-aef7-1afc684d5384
21/08/17 05:38:44 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-82e4df59-e01f-4652-a6e7-f4954c0355e6
[student782_3@bigdataanalytics2-worker-shdpt-v31-1-0 ~]$
